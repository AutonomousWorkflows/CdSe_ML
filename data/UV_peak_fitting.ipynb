{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34027957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Peak fitting for CdSe (UV-Vis)\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pybaselines as pybase\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9af35e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Wavelengths as np array\n",
    "with open(r\"UV-visWavelengths.csv\") as UV_WL:\n",
    "    wavelengths = np.loadtxt(UV_WL, delimiter=\",\")\n",
    "    electronvolts = 1239.84193/wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02b7caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Intensity data\n",
    "from numpy import genfromtxt\n",
    "data = genfromtxt(r\"CdSe UV DoE.csv\", delimiter=',')\n",
    "Abs_data = np.nan_to_num(data, nan=0, posinf=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07bae106",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find lowest energy peak in spectra\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "import pybaselines as pybase\n",
    "\n",
    "def findUV(y,wavelengths):\n",
    "    #clean data to remove nan and inf\n",
    "    m = np.stack((wavelengths,y),axis=0)\n",
    "    m = np.transpose(m)\n",
    "    m = (m[~np.isnan(m).any(axis=1), :])\n",
    "    m = (m[~np.isinf(m).any(axis=1), :])\n",
    "    wavelengths = m[:,0]\n",
    "    y = m[:,1]\n",
    "    #Smooth curves with Whittaker Eilers\n",
    "    [y_base,_] = pybase.whittaker.aspls(y, lam=1000000000.0, diff_order=2, max_iter=100, tol=0.001, weights=None, alpha=None)\n",
    "    [y_filt,_] = pybase.whittaker.aspls(y, lam=100000.0, diff_order=2, max_iter=100, tol=0.001, weights=None, alpha=None)\n",
    "    #Subtract the minimum (<600nm)\n",
    "    y = y - np.ndarray.min(y_base[550:1450])\n",
    "    y_filt = y_filt - np.ndarray.min(y_base[550:1450])\n",
    "    #Take derivative and smooth with Whittaker Eilers\n",
    "    dydx = np.diff(y_filt)/np.diff(wavelengths)\n",
    "    [dydx_filt,_] = pybase.whittaker.aspls(dydx, lam=100000.0, diff_order=2, max_iter=100, tol=0.001, weights=None, alpha=None)\n",
    "    #Take derivative and smooth with Whittaker Eilers (double derivative)\n",
    "    d2ydx2 = np.diff(dydx_filt)/np.diff(wavelengths)[1:]\n",
    "    [d2ydx2_filt,_] = pybase.whittaker.aspls(d2ydx2, lam=50000.0, diff_order=2, max_iter=100, tol=0.001, weights=None, alpha=None)\n",
    "    d2ydx2_raw = np.diff(dydx)/np.diff(wavelengths)[1:]\n",
    "    d2ydx2_raw_cut = d2ydx2_raw[550:1450]\n",
    "    d2ydx2_cut = d2ydx2_filt[550:1450]\n",
    "    #Find peaks in wavelength range\n",
    "    #Find peaks from raw curve (if peaks exist)\n",
    "    from scipy.signal import find_peaks, peak_prominences\n",
    "    peaks, _ = find_peaks(y_filt[550:1450])\n",
    "    prominences = peak_prominences(y_filt[550:1450], peaks)[0]\n",
    "    abs_heights = y_filt[550:1450][peaks]\n",
    "    #Sort by most prominent peaks (prominences, wavelengths, y_filt heights, peak indices, zero column, peaks (in y_filt))\n",
    "    a1 = np.stack((prominences,wavelengths[550:1450][peaks],abs_heights,peaks,np.zeros(np.shape(peaks)[0]),np.zeros(np.shape(peaks)[0]),y_filt[550:1450][peaks]),axis=0)\n",
    "    a1 = np.transpose(a1)\n",
    "    a1 = np.delete(a1, np.where(a1[:,-1] <= 0.001)[0], axis=0)\n",
    "    a1 = a1[a1[:, 0].argsort()]\n",
    "\n",
    "    peaks, _ = find_peaks(-d2ydx2_cut)\n",
    "    prominences = peak_prominences(-d2ydx2_cut, peaks)[0]\n",
    "    abs_heights = -d2ydx2_cut[peaks] \n",
    "    #Sort by most prominent peaks (prominences, wavelengths, d2ydx2 heights, peak indices, zero column, peaks (in y_filt))\n",
    "    a2 = np.stack((prominences,wavelengths[550:1450][peaks],abs_heights,peaks,np.zeros(np.shape(peaks)[0]),np.zeros(np.shape(peaks)[0]),y_filt[550:1450][peaks]),axis=0)\n",
    "    a2 = np.transpose(a2)\n",
    "    a2 = np.delete(a2, np.where(a2[:,-1] <= 0.001)[0], axis=0)\n",
    "    a2 = a2[a2[:, 0].argsort()]\n",
    "\n",
    "    \n",
    "    #Remove peaks right of most prominent peak\n",
    "    sorted_peaks1 = a1[a1[:,1] <= a1 [-1:,1]]\n",
    "    sorted_peaks2 = a2[a2[:,1] <= a2 [-1:,1]]\n",
    "    if np.shape(a1)[0] > 0:\n",
    "        sorted_peaks = np.stack((sorted_peaks1[-1,:]  , sorted_peaks2[-1,:]))\n",
    "    if np.shape(a1)[0] == 0:\n",
    "        sorted_peaks = sorted_peaks2\n",
    "    #Get the two other peaks left of most prominent peak\n",
    "    b = np.zeros(7)\n",
    "    if np.shape(sorted_peaks)[0] > 0:\n",
    "        b = sorted_peaks[sorted_peaks[:, 3].argsort()]\n",
    "        b = b[-1,:]  \n",
    "    #print(b)\n",
    "    #Estimate fwhm using points where curve cuts zero\n",
    "    if np.shape(sorted_peaks)[0] > 0:\n",
    "        zero_crossings = np.where(np.diff(np.sign(d2ydx2_cut)))[0]\n",
    "        idx = zero_crossings[np.argmax(zero_crossings>b[3])]\n",
    "        fwhm = 2*(wavelengths[550:1450][idx]-b[1])\n",
    "        b[4] = idx\n",
    "        b[5] = fwhm   \n",
    "    #Extract parameters of wavelength (mu), fwhm (nm) and height\n",
    "    #Sort Parameters\n",
    "    est_parameters = [b[1],b[5],b[6]]\n",
    "    #print(est_parameters)\n",
    "\n",
    "    #Plot smoothed Abs\n",
    "    fig = plt.figure(figsize=(4, 4), dpi=80)\n",
    "    plt.title('Smoothed Abs')\n",
    "    plt.plot(wavelengths[550:1450],y[550:1450])\n",
    "    plt.plot(wavelengths[550:1450],y_filt[550:1450])\n",
    "    \n",
    "    # Function to model and create data\n",
    "    def gaussian(x, mu, fwhm, height):\n",
    "        sig = abs(fwhm/2.35482004503)\n",
    "        return height*np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "    # Generating clean data\n",
    "    k = [b[3], b[4]]\n",
    "    k = np.int_(k)\n",
    "    x = wavelengths[550:1450][k[0]-20:k[1]+120]\n",
    "    est = gaussian(x, b[1], b[5], b[6])\n",
    "    #yn = y_filt[550:1450][k[0]:k[1]+100]\n",
    "    yn = y[550:1450][k[0]-20:k[1]+120]\n",
    "\n",
    "    # Executing curve_fit on noisy data\n",
    "    try:\n",
    "        popt, pcov = curve_fit(gaussian, x, yn, [b[1], abs(b[5]), b[6]])\n",
    "        return([popt[0],popt[1],popt[2],1239.84193/popt[0],2*((1239.84193/popt[0])-1239.84193/(popt[0]+0.5*popt[1])),popt[2]])\n",
    "    except:\n",
    "        return([0,0,0,0,0,0])\n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Peak fit on dataset\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "np.set_printoptions(edgeitems=8, precision=3, suppress=True, threshold=5)\n",
    "parameters = np.zeros((np.shape(Abs_data)[0],13))\n",
    "index = 0\n",
    "for row in Abs_data:\n",
    "    print(index+1)\n",
    "#Baseline correction to compare with first UV spectra for every reaction\n",
    "    if np.remainder(index+1, 20) == 1: \n",
    "        Abs0 = Abs_data[index,7:]\n",
    "        [Abs0_filt,_] = pybase.whittaker.aspls(Abs0, lam=100000000.0, diff_order=2, max_iter=100, tol=0.001, weights=None, alpha=None)\n",
    "        Abs2 = Abs_data[index+1,7:]\n",
    "        [Abs2_filt,_] = pybase.whittaker.aspls(Abs2, lam=100000000.0, diff_order=2, max_iter=100, tol=0.001, weights=None, alpha=None)\n",
    "        Abs_diff = Abs2_filt - Abs0_filt\n",
    "        a = np.ndarray.min(Abs_diff[550:1450])\n",
    "        Abs_diff = Abs_diff-a\n",
    "        idx_max = np.argmax(Abs_diff[550:1450])\n",
    "        print(idx_max)\n",
    "        idx_cut = np.argmax(Abs_diff[550+idx_max:1450]<0.002)\n",
    "        print(idx_cut)\n",
    "        master_idx = idx_cut + 200\n",
    "        Abs = Abs0\n",
    "    if np.remainder(index+1, 20) != 1: \n",
    "        master_idx = idx_cut + 100\n",
    "        Abs = Abs_data[index,7:]\n",
    "    \n",
    "    Baseline_correction = Abs0_filt\n",
    "    Baseline_correction[0:550+master_idx] = Abs0_filt[550+master_idx]\n",
    "    Abs_corrected = Abs - Baseline_correction\n",
    "\n",
    "    \n",
    "    Analyze_WL = findUV(Abs_corrected,wavelengths)\n",
    "    parameters[index,:7]=Abs_data[index,:7]\n",
    "    parameters[index,7:13] = Analyze_WL\n",
    "    print(parameters[index,:7])\n",
    "    print(parameters[index,7:13])\n",
    "    #time.sleep(1)\n",
    "    plt.show()\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d02d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save raw data\n",
    "np.savetxt(\"CdSe UV fitting (DoE raw).csv\", parameters, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548d89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import raw data\n",
    "from numpy import genfromtxt\n",
    "data = genfromtxt(r\"CdSe UV fitting (DoE raw).csv\", delimiter=',')\n",
    "Fit_data = abs(np.nan_to_num(data, nan=0, posinf=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f072a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning of data to remove points which are unreasonable\n",
    "index = 0\n",
    "for row in Fit_data:\n",
    "    if Fit_data[index,7] == 0 or Fit_data[index,10] == 0: #Check for zeros\n",
    "        Fit_data[index,:] = np.zeros((1,13))\n",
    "    elif Fit_data[index,7] < 400 or Fit_data[index,7] > 630: #Check feasibility of wavelength\n",
    "        Fit_data[index,:] = np.zeros((1,13))\n",
    "    elif abs(Fit_data[index,8]) < 18 or abs(Fit_data[index,8]) > 80: #Check feasibility of FWHM\n",
    "        Fit_data[index,:] = np.zeros((1,13))\n",
    "    elif Fit_data[index,11] > 0.5: #Check feasibility of FWHM in eV\n",
    "        Fit_data[index,:] = np.zeros((1,13))\n",
    "    elif Fit_data[index,12] > 1.2 or Fit_data[index,12] < 0.02: #Check feasibility of height in eV\n",
    "        Fit_data[index,:] = np.zeros((1,13))\n",
    "    index += 1\n",
    "Clean_fit = Fit_data[~np.all(Fit_data == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb1688a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save cleaned data\n",
    "np.savetxt(\"CdSe UV fitting (DoE cleaned).csv\", Clean_fit, delimiter=\",\",fmt='%1.3f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
